{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "torch.manual_seed(0)#make training results repeatable \n",
    "\n",
    "\n",
    "def vector_print(vector, end='\\n'):\n",
    "    vectorString = \", \".join([f'{element:7.2f}' for element in vector])\n",
    "    print(vectorString, end=end)\n",
    "\n",
    "    \n",
    "class Ghost_Batch_Norm(nn.Module): #https://arxiv.org/pdf/1705.08741v2.pdf has what seem like typos in GBN definition. \n",
    "    def __init__(self, features, ghost_batch_size=32, number_of_ghost_batches=64, n_averaging=1, stride=1, eta=0.9, bias=True, device='cpu', name='', conv=False, features_out=None):\n",
    "        super(Ghost_Batch_Norm, self).__init__()\n",
    "        self.name = name\n",
    "        self.index = None\n",
    "        self.stride = stride\n",
    "        self.device = device\n",
    "        self.features = features\n",
    "        self.features_out = features_out if features_out is not None else self.features\n",
    "        self.register_buffer('ghost_batch_size', torch.tensor(ghost_batch_size, dtype=torch.long))\n",
    "        self.register_buffer('n_ghost_batches', torch.tensor(number_of_ghost_batches*n_averaging, dtype=torch.long))\n",
    "        self.conv = False\n",
    "        self.gamma = None\n",
    "        self.bias = None\n",
    "        self.updates = 0\n",
    "        if conv:\n",
    "            self.conv = nn.Conv1d(self.features, self.features_out, stride, stride=stride, bias=bias)\n",
    "        else:\n",
    "            self.gamma = nn.Parameter(torch .ones(self.features))\n",
    "            if bias:\n",
    "                self.bias = nn.Parameter(torch.zeros(self.features))\n",
    "        self.running_stats = True\n",
    "        self.initialized   = False\n",
    "\n",
    "        self.register_buffer('eps',  torch.tensor(1e-5, dtype=torch.float))\n",
    "        self.register_buffer('eta',  torch.tensor(eta, dtype=torch.float))\n",
    "        self.register_buffer('m',    torch.zeros((1,1,self.stride,self.features), dtype=torch.float))\n",
    "        self.register_buffer('s',    torch.ones ((1,1,self.stride,self.features), dtype=torch.float))\n",
    "        self.register_buffer('zero', torch.tensor(0., dtype=torch.float))\n",
    "        self.register_buffer('one',  torch.tensor(1., dtype=torch.float))\n",
    "        self.register_buffer('two',  torch.tensor(2., dtype=torch.float))\n",
    "\n",
    "    def print(self):\n",
    "        print('-'*50)\n",
    "        print(self.name)\n",
    "        for i in range(self.stride):\n",
    "            print(\" mean \",end='')\n",
    "            vector_print(self.m[0,0,i,:])\n",
    "        for i in range(self.stride):\n",
    "            print(\"  std \", end='')\n",
    "            vector_print(self.s[0,0,i,:])\n",
    "        if self.gamma is not None:\n",
    "            print(\"gamma \", end='')\n",
    "            vector_print(self.gamma.data)\n",
    "            if self.bias is not None:\n",
    "                print(\" bias \", end='')\n",
    "                vector_print(self.bias.data)\n",
    "        print()\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def set_mean_std(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        pixels = x.shape[2]\n",
    "        pixel_groups = torch.div(pixels, self.stride, rounding_mode='trunc')\n",
    "        x = x.detach().transpose(1,2).contiguous().view(batch_size*pixels, 1, self.features)\n",
    "        # this won't work for any layers with stride!=1\n",
    "        x = x.view(-1, 1, self.stride, self.features)            \n",
    "        m64 = x.mean(dim=0, keepdim=True, dtype=torch.float64)#.to(self.device)\n",
    "        self.m = m64.type(torch.float32).to(self.device)\n",
    "        self.s = x .std(dim=0, keepdim=True).to(self.device)\n",
    "        self.initialized = True\n",
    "        self.running_stats = False\n",
    "        self.print()        \n",
    "\n",
    "    def set_ghost_batches(self, n_ghost_batches):\n",
    "        self.n_ghost_batches = torch.tensor(n_ghost_batches, dtype=torch.long).to(self.device)\n",
    "\n",
    "    def forward(self, x, debug=False):\n",
    "        batch_size = x.shape[0]\n",
    "        pixels = x.shape[2]\n",
    "        pixel_groups = pixels//self.stride\n",
    "\n",
    "        if self.training and self.n_ghost_batches!=0:\n",
    "            self.ghost_batch_size = torch.div(batch_size, self.n_ghost_batches.abs(), rounding_mode = 'trunc')\n",
    "\n",
    "            #\n",
    "            # Apply batch normalization with Ghost Batch statistics\n",
    "            #\n",
    "            x = x.transpose(1,2).contiguous().view(self.n_ghost_batches.abs(), self.ghost_batch_size*pixel_groups, self.stride, self.features)\n",
    "            \n",
    "            gbm =  x.mean(dim=1, keepdim=True)\n",
    "            gbs = (x. var(dim=1, keepdim=True) + self.eps).sqrt()\n",
    "\n",
    "            #\n",
    "            # Keep track of running mean and standard deviation. \n",
    "            #\n",
    "            if self.running_stats or debug:\n",
    "                # Use mean over ghost batches for running mean and std\n",
    "                bm = gbm.detach().mean(dim=0, keepdim=True)\n",
    "                bs = gbs.detach().mean(dim=0, keepdim=True)\n",
    "\n",
    "                if debug and self.initialized:\n",
    "                    gbms = gbm.detach().std(dim=0, keepdim=True)\n",
    "                    gbss = gbs.detach().std(dim=0, keepdim=True)\n",
    "                    m_pulls = (bm-self.m)/gbms\n",
    "                    s_pulls = (bs-self.s)/gbss\n",
    "                    #s_ratio = bs/self.s\n",
    "                    #if (m_pulls.abs()>5).any() or (s_pulls.abs()>5).any():\n",
    "                    print()\n",
    "                    print(self.name)\n",
    "                    print('self.m\\n',self.m)\n",
    "                    print('    bm\\n', bm)\n",
    "                    print('  gbms\\n',gbms)\n",
    "                    print('m_pulls\\n',m_pulls,m_pulls.abs().mean(),m_pulls.abs().max())\n",
    "                    print('-------------------------')\n",
    "                    print('self.s\\n',self.s)\n",
    "                    print('    bs\\n',bs)\n",
    "                    print('  gbss\\n',gbss)\n",
    "                    print('s_pulls\\n',s_pulls,s_pulls.abs().mean(),s_pulls.abs().max())\n",
    "                    #print('s_ratio\\n',s_ratio)\n",
    "                    print()\n",
    "                    #input()\n",
    "                    \n",
    "            if self.running_stats:\n",
    "                # Simplest possible method\n",
    "                if self.initialized:\n",
    "                    self.m = self.eta*self.m + (self.one-self.eta)*bm\n",
    "                    self.s = self.eta*self.s + (self.one-self.eta)*bs\n",
    "                else:\n",
    "                    self.m = self.zero*self.m+bm\n",
    "                    self.s = self.zero*self.s+bs\n",
    "                    self.initialized = True\n",
    "\n",
    "            if self.n_ghost_batches>0:\n",
    "                x = x - gbm\n",
    "                x = x / gbs\n",
    "            else:\n",
    "                x = x.view(batch_size, pixel_groups, self.stride, self.features)\n",
    "                x = x - self.m\n",
    "                x = x / self.s\n",
    "                \n",
    "        else:\n",
    "            # Use mean and standard deviation buffers rather than batch statistics\n",
    "            #.view(self.n_ghost_batches, self.ghost_batch_size*pixel_groups, self.stride, self.features)\n",
    "            x = x.transpose(1,2).view(batch_size, pixel_groups, self.stride, self.features)\n",
    "            x = x - self.m\n",
    "            x = x / self.s\n",
    "\n",
    "        if self.conv:\n",
    "            # back to standard indexing for convolutions: [batch, feature, pixel]\n",
    "            x = x.view(batch_size, pixels, self.features).transpose(1,2).contiguous()\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = x * self.gamma\n",
    "            if self.bias is not None:\n",
    "                x = x + self.bias\n",
    "            # back to standard indexing for convolutions: [batch, feature, pixel]\n",
    "            x = x.view(batch_size, pixels, self.features).transpose(1,2).contiguous()\n",
    "        return x            \n",
    "\n",
    "    \n",
    "#\n",
    "# some basic four-vector operations\n",
    "#\n",
    "def PxPyPzE(v): # need this to be able to add four-vectors\n",
    "    pt  = v[:,0:1]\n",
    "    eta = v[:,1:2]\n",
    "    phi = v[:,2:3]\n",
    "    m   = v[:,3:4]\n",
    "    \n",
    "    Px, Py, Pz = pt*phi.cos(), pt*phi.sin(), pt*eta.sinh()\n",
    "    E = (pt**2 + Pz**2 + m**2).sqrt()\n",
    "\n",
    "    return torch.cat( (Px,Py,Pz,E), 1 )\n",
    "\n",
    "\n",
    "def PtEtaPhiM(v):\n",
    "    px = v[:,0:1]\n",
    "    py = v[:,1:2]\n",
    "    pz = v[:,2:3]\n",
    "    e  = v[:,3:4]\n",
    "\n",
    "    Pt  = (px**2+py**2).sqrt()\n",
    "    ysign = py.sign()\n",
    "    ysign = ysign + (ysign==0.0).float() # if py==0, px==Pt and acos(1)=pi/2 so we need zero protection on py.sign()\n",
    "    Phi = (px/Pt).acos() * ysign\n",
    "    Eta = (pz/Pt).asinh()\n",
    "\n",
    "    M = F.relu(e**2 - px**2 - py**2 - pz**2).sqrt()\n",
    "\n",
    "    return torch.cat( (Pt, Eta, Phi, M) , 1 ) \n",
    "    \n",
    "\n",
    "def addFourVectors(v1, v2, v1PxPyPzE=None, v2PxPyPzE=None): # output added four-vectors\n",
    "    #vX[batch index, (pt,eta,phi,m), object index]\n",
    "\n",
    "    if v1PxPyPzE is None:\n",
    "        v1PxPyPzE = PxPyPzE(v1)\n",
    "    if v2PxPyPzE is None:\n",
    "        v2PxPyPzE = PxPyPzE(v2)\n",
    "\n",
    "    v12PxPyPzE = v1PxPyPzE + v2PxPyPzE\n",
    "    v12        = PtEtaPhiM(v12PxPyPzE)\n",
    "\n",
    "    return v12, v12PxPyPzE\n",
    "\n",
    "\n",
    "#\n",
    "# Some different non-linear units\n",
    "#\n",
    "def SiLU(x): #SiLU https://arxiv.org/pdf/1702.03118.pdf   Swish https://arxiv.org/pdf/1710.05941.pdf\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def NonLU(x): #Pick the default non-Linear Unit\n",
    "    return SiLU(x) # often slightly better performance than standard ReLU\n",
    "    #return F.relu(x)\n",
    "    #return F.rrelu(x, training=training)\n",
    "    #return F.leaky_relu(x, negative_slope=0.1)\n",
    "    #return F.elu(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# embed inputs in feature space\n",
    "#\n",
    "class Input_Embed(nn.Module):\n",
    "    def __init__(self, dimension, device='cpu'):\n",
    "        super(Input_Embed, self).__init__()\n",
    "        self.d = dimension\n",
    "        self.device = device\n",
    "\n",
    "        # embed inputs to dijetResNetBlock in target feature space\n",
    "        self.jet_embed     = Ghost_Batch_Norm(3, features_out=self.d, conv=True, name='jet embedder', device=self.device) # phi is relative to dijet, mass is zero in toy data\n",
    "        self.jet_conv      = Ghost_Batch_Norm(self.d, conv=True, name='jet convolution', device = self.device)\n",
    "\n",
    "        self.dijet_embed   = Ghost_Batch_Norm(4, features_out=self.d, conv=True, name='dijet embedder', device = self.device) # phi is relative to quadjet\n",
    "        self.dijet_conv    = Ghost_Batch_Norm(self.d, conv=True, name='dijet convolution', device = self.device) \n",
    "\n",
    "        self.quadjet_embed = Ghost_Batch_Norm(3, features_out=self.d, conv=True, name='quadjet embedder', device = self.device) # phi is removed\n",
    "        self.quadjet_conv  = Ghost_Batch_Norm(self.d, conv=True, name='quadjet convolution', device = self.device)\n",
    "\n",
    "        self.register_buffer('tau', torch.tensor(math.tau, dtype=torch.float))\n",
    "\n",
    "    def calcDeltaPhi(self, v1, v2): #expects eta, phi representation\n",
    "        dPhi12 = (v1[:,2:3]-v2[:,2:3])%self.tau\n",
    "        dPhi21 = (v2[:,2:3]-v1[:,2:3])%self.tau\n",
    "        dPhi = torch.min(dPhi12,dPhi21)\n",
    "        return dPhi\n",
    "        \n",
    "    def data_prep(self, j):\n",
    "        j = j.clone()# prevent overwritting data from dataloader when doing operations directly from RAM rather than copying to VRAM\n",
    "        j = j.view(-1,4,4)\n",
    "\n",
    "        # make leading jet eta positive direction so detector absolute eta info is removed\n",
    "        etaSign = 1-2*(j[:,1,0:1]<0).float() # -1 if eta is negative, +1 if eta is zero or positive\n",
    "        j[:,1,:] = etaSign * j[:,1,:]\n",
    "        \n",
    "        d, dPxPyPzE = addFourVectors(j[:,:,(0,2,0,1,0,1)], \n",
    "                                     j[:,:,(1,3,2,3,3,2)])\n",
    "\n",
    "        q, qPxPyPzE = addFourVectors(d[:,:,(0,2,4)],\n",
    "                                     d[:,:,(1,3,5)], \n",
    "                                     v1PxPyPzE = dPxPyPzE[:,:,(0,2,4)],\n",
    "                                     v2PxPyPzE = dPxPyPzE[:,:,(1,3,5)])        \n",
    "\n",
    "        # take log of pt, mass variables which have long tails\n",
    "        j[:,(0,3),:] = torch.log(1+j[:,(0,3),:])\n",
    "        d[:,(0,3),:] = torch.log(1+d[:,(0,3),:])\n",
    "        q[:,(0,3),:] = torch.log(1+q[:,(0,3),:])\n",
    "\n",
    "        # set up all possible jet pairings\n",
    "        j = torch.cat([j, j[:,:,(0,2,1,3)], j[:,:,(0,3,1,2)]],2)\n",
    "\n",
    "        # only keep relative angular information so that learned features are invariant under global phi rotations and eta/phi flips\n",
    "        j[:,2:3,(0,2,4,6,8,10)] = self.calcDeltaPhi(d, j[:,:,(0,2,4,6,8,10)]) # replace jet phi with deltaPhi between dijet and jet\n",
    "        j[:,2:3,(1,3,5,7,9,11)] = self.calcDeltaPhi(d, j[:,:,(1,3,5,7,9,11)])\n",
    "\n",
    "        d[:,2:3,(0,2,4)] = self.calcDeltaPhi(q, d[:,:,(0,2,4)])\n",
    "        d[:,2:3,(1,3,4)] = self.calcDeltaPhi(q, d[:,:,(1,3,5)])\n",
    "\n",
    "        q = torch.cat( (q[:,:2,:],q[:,3:,:]) , 1 ) # remove phi from quadjet features\n",
    "\n",
    "        return j, d, q\n",
    "\n",
    "    def set_mean_std(self, j):\n",
    "        j, d, q = self.data_prep(j)\n",
    "\n",
    "        self    .jet_embed.set_mean_std(j[:,0:3])#mass is always zero in toy data\n",
    "        self  .dijet_embed.set_mean_std(d)\n",
    "        self.quadjet_embed.set_mean_std(q)\n",
    "\n",
    "    def set_ghost_batches(self, n_ghost_batches):\n",
    "        self.    jet_embed.set_ghost_batches(n_ghost_batches)\n",
    "        self.  dijet_embed.set_ghost_batches(n_ghost_batches)\n",
    "        self.quadjet_embed.set_ghost_batches(n_ghost_batches)\n",
    "\n",
    "        self.    jet_conv.set_ghost_batches(n_ghost_batches)\n",
    "        self.  dijet_conv.set_ghost_batches(n_ghost_batches)\n",
    "        self.quadjet_conv.set_ghost_batches(n_ghost_batches)\n",
    "\n",
    "    def forward(self, j):\n",
    "        j, d, q = self.data_prep(j)\n",
    "\n",
    "        j = self    .jet_embed(j[:,0:3])#mass is always zero in toy data\n",
    "        d = self  .dijet_embed(d)\n",
    "        q = self.quadjet_embed(q)\n",
    "\n",
    "        j = self    .jet_conv(NonLU(j))\n",
    "        d = self  .dijet_conv(NonLU(d))\n",
    "        q = self.quadjet_conv(NonLU(q))\n",
    "\n",
    "        return j, d, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Basic_CNN(nn.Module):\n",
    "    def __init__(self, dimension, n_classes=2, device='cpu'):\n",
    "        super(Basic_CNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.d = dimension\n",
    "        self.n_classes = n_classes\n",
    "        self.n_ghost_batches = 64\n",
    "\n",
    "        self.name = f'Basic_CNN_{self.d}'\n",
    "\n",
    "        self.input_embed = Input_Embed(self.d)\n",
    "\n",
    "        self.jets_to_dijets     = Ghost_Batch_Norm(self.d, stride=2, conv=True, device = self.device)\n",
    "        self.dijets_to_quadjets = Ghost_Batch_Norm(self.d, stride=2, conv=True, device = self.device)\n",
    "\n",
    "        self.select_q = Ghost_Batch_Norm(self.d, features_out=1, conv=True, bias=False, device = self.device)\n",
    "        self.out      = Ghost_Batch_Norm(self.d, features_out=self.n_classes, conv=True, device = self.device)\n",
    "\n",
    "    def set_mean_std(self, j):\n",
    "        self.input_embed.set_mean_std(j)\n",
    "\n",
    "    def set_ghost_batches(self, n_ghost_batches):\n",
    "        self.input_embed.set_ghost_batches(n_ghost_batches)\n",
    "        self.jets_to_dijets.set_ghost_batches(n_ghost_batches)\n",
    "        self.dijets_to_quadjets.set_ghost_batches(n_ghost_batches)\n",
    "        self.select_q.set_ghost_batches(n_ghost_batches)\n",
    "        self.out.set_ghost_batches(n_ghost_batches)\n",
    "        self.n_ghost_batches = n_ghost_batches\n",
    "\n",
    "    def forward(self, j):\n",
    "        print(j.shape)\n",
    "        j, d, q = self.input_embed(j)\n",
    "        print('j shape:', j.shape)\n",
    "        d = d + NonLU(self.jets_to_dijets(j))\n",
    "        q = q + NonLU(self.dijets_to_quadjets(d))\n",
    "        print('q shape:', q.shape)\n",
    "        #compute a score for each event quadjet\n",
    "        q_logits = self.select_q(q)\n",
    "        \n",
    "        print('q_logits shape:', q_logits.shape)\n",
    "        #convert the score to a 'probability' with softmax. This way the classifier is learning which pairing is most relevant to the classification task at hand.\n",
    "        q_score = F.softmax(q_logits, dim=-1)\n",
    "        q_logits = q_logits.view(-1, 3)\n",
    "\n",
    "        #add together the quadjets with their corresponding probability weight\n",
    "        e = torch.matmul(q, q_score.transpose(1,2))\n",
    "        print('e shape:', e.shape)\n",
    "        #project the final event-level pixel into the class score space\n",
    "        c_logits = self.out(e)\n",
    "        print('c_logits shape:', c_logits.shape)\n",
    "        c_logits = c_logits.view(-1, self.n_classes)\n",
    "\n",
    "        print('output shape:', c_logits.shape, q_logits.shape)\n",
    "        return c_logits, q_logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_AE(nn.Module):\n",
    "    def __init__(self, dimension, out_features = 16, device = 'cpu'):\n",
    "        super(CNN_AE, self).__init__()\n",
    "        self.device = device\n",
    "        self.d = dimension\n",
    "        self.out_features = out_features\n",
    "        self.n_ghost_batches = 64\n",
    "\n",
    "        self.name = f'CNN_AE_{self.d}'\n",
    "\n",
    "        self.input_embed = Input_Embed(self.d)\n",
    "        self.jets_to_dijets     = Ghost_Batch_Norm(self.d, stride=2, conv=True, device = self.device)\n",
    "        self.dijets_to_quadjets = Ghost_Batch_Norm(self.d, stride=2, conv=True, device = self.device)\n",
    "        \n",
    "        self.select_q = Ghost_Batch_Norm(self.d, features_out=1, conv=True, bias=False, device = self.device)\n",
    "\n",
    "        self.out      = Ghost_Batch_Norm(self.d, features_out=self.out_features, conv=True, device = self.device)\n",
    "\n",
    "    \n",
    "    def set_mean_std(self, j):\n",
    "        self.input_embed.set_mean_std(j)\n",
    "\n",
    "    \n",
    "    def set_ghost_batches(self, n_ghost_batches):\n",
    "        self.input_embed.set_ghost_batches(n_ghost_batches)\n",
    "        self.jets_to_dijets.set_ghost_batches(n_ghost_batches)\n",
    "        self.dijets_to_quadjets.set_ghost_batches(n_ghost_batches)\n",
    "        self.select_q.set_ghost_batches(n_ghost_batches)\n",
    "        self.out.set_ghost_batches(n_ghost_batches)\n",
    "        self.n_ghost_batches = n_ghost_batches\n",
    "    \n",
    "    def forward(self, j):\n",
    "        print(j.shape)\n",
    "        j, d, q = self.input_embed(j)\n",
    "        print('j shape:', j.shape)\n",
    "        \n",
    "        d = d + NonLU(self.jets_to_dijets(j))\n",
    "        q = q + NonLU(self.dijets_to_quadjets(d))\n",
    "        print('q shape:', q.shape)\n",
    "        #compute a score for each event quadjet\n",
    "        q_logits = self.select_q(q)\n",
    "        \n",
    "        print('q_logits shape:', q_logits.shape)\n",
    "        #convert the score to a 'probability' with softmax. This way the classifier is learning which pairing is most relevant to the classification task at hand.\n",
    "        q_score = F.softmax(q_logits, dim=-1)\n",
    "        q_logits = q_logits.view(-1, 3)\n",
    "        \n",
    "        #add together the quadjets with their corresponding probability weight\n",
    "        e = torch.matmul(q, q_score.transpose(1,2))\n",
    "        print('e shape:', e.shape)\n",
    "        rec_j = NonLU(self.out(e)).view(-1, 4, 4)\n",
    "\n",
    "        print('output shape:', rec_j.shape)\n",
    "\n",
    "        return rec_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = torch.randn(16384, 4, 4)\n",
    "\n",
    "basic = Basic_CNN(8, 16)\n",
    "AE = CNN_AE(8, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1258, -1.1524, -0.2506, -0.4339],\n",
       "         [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
       "         [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
       "         [ 0.1198,  1.2377,  1.1168, -0.2473]],\n",
       "\n",
       "        [[-1.3527, -1.6959,  0.5667,  0.7935],\n",
       "         [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
       "         [ 0.7502, -0.5855, -0.1734,  0.1835],\n",
       "         [ 1.3894,  1.5863,  0.9463, -0.8437]],\n",
       "\n",
       "        [[-0.6136,  0.0316, -0.4927,  0.2484],\n",
       "         [ 0.4397,  0.1124,  0.6408,  0.4412],\n",
       "         [-0.1023,  0.7924, -0.2897,  0.0525],\n",
       "         [ 0.5229,  2.3022, -1.4689, -1.5867]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9364, -1.4689,  0.9887, -0.3964],\n",
       "         [ 0.4679,  0.1041, -0.0475, -0.3481],\n",
       "         [ 0.2628,  0.4390,  0.5952,  1.1925],\n",
       "         [-1.9599, -1.9036, -0.5388,  0.6060]],\n",
       "\n",
       "        [[-0.1516,  1.2354,  0.1238,  0.7826],\n",
       "         [ 0.5779,  0.5674,  0.1776,  1.3461],\n",
       "         [-1.0992, -0.1250,  0.5286, -1.3170],\n",
       "         [ 0.3979, -0.1638,  0.0296, -0.0861]],\n",
       "\n",
       "        [[ 0.2645,  0.0257, -0.9452, -2.1030],\n",
       "         [-0.3210, -0.0038,  0.6612,  0.1100],\n",
       "         [ 1.0514, -0.1596,  0.1765, -1.0886],\n",
       "         [-0.6057, -0.1800, -1.2139,  0.0769]]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = j.view(-1,4,4)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8487,  0.6920, -0.3160, -2.1152],\n",
       "        [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
       "        [ 0.4397,  0.1124,  0.6408,  0.4412],\n",
       "        ...,\n",
       "        [ 0.4679,  0.1041, -0.0475, -0.3481],\n",
       "        [ 0.5779,  0.5674,  0.1776,  1.3461],\n",
       "        [-0.3210, -0.0038,  0.6612,  0.1100]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic:\n",
      "torch.Size([16384, 4, 4])\n",
      "j shape: torch.Size([16384, 8, 12])\n",
      "q shape: torch.Size([16384, 8, 3])\n",
      "q_logits shape: torch.Size([16384, 1, 3])\n",
      "e shape: torch.Size([16384, 8, 1])\n",
      "c_logits shape: torch.Size([16384, 16, 1])\n",
      "output shape: torch.Size([16384, 16]) torch.Size([16384, 3])\n",
      "\n",
      "AE:\n",
      "torch.Size([16384, 4, 4])\n",
      "j shape: torch.Size([16384, 8, 12])\n",
      "q shape: torch.Size([16384, 8, 3])\n",
      "q_logits shape: torch.Size([16384, 1, 3])\n",
      "e shape: torch.Size([16384, 8, 1])\n",
      "output shape: torch.Size([16384, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nBasic:')\n",
    "basic(j)\n",
    "print('\\nAE:')\n",
    "AE(j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems ok, given that the ouput should be four jets with three features each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
